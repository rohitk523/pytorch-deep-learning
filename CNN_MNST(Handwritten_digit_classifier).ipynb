{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIJ01SD4ltfanwYhnXN5yw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitk523/pytorch-deep-learning/blob/main/CNN_MNST(Handwritten_digit_classifier).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "toA2mSgbEBUd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Gg2OHKYmEBLl"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "Wkzl6GtDEAmX"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "image, label = next(dataiter)\n",
        "label, image.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW71DWguOgJj",
        "outputId": "f79324f2-0f2d-40a1-a6af-f10b30e34ed0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 7, 4, 6, 6, 6, 5, 5, 7, 9, 4, 6, 7, 7, 9, 7, 7, 9, 3, 7, 5, 6, 1, 6,\n",
              "         2, 4, 8, 1, 6, 8, 3, 9, 8, 2, 2, 8, 5, 0, 7, 5, 6, 7, 1, 8, 7, 5, 8, 1,\n",
              "         0, 4, 2, 4, 1, 5, 1, 7, 2, 2, 5, 7, 7, 4, 4, 6]),\n",
              " torch.Size([64, 1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25YOEHikDeni",
        "outputId": "1d19ff7a-d561-4a7f-e0c5-abfc7f2b9949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# we have CNN architecture for handwritten digit classifier, we need all other things\n",
        "\n",
        "# class Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "#         self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "#         self.dropout1 = nn.Dropout(0.25)\n",
        "#         self.dropout2 = nn.Dropout(0.5)\n",
        "#         self.fc1 = nn.Linear(9216, 128)\n",
        "#         self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.conv2(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = F.max_pool2d(x, 2)\n",
        "#         x = self.dropout1(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc1(x)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.dropout2(x)\n",
        "#         x = self.fc2(x)\n",
        "#         output = F.log_softmax(x, dim=1)\n",
        "#         return output\n",
        "\n",
        "# This is LeNet architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # C1: Convolutional layer (input channels = 1, output channels = 6, kernel size = 5)\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "\n",
        "        # C3: Convolutional layer (input channels = 6, output channels = 16, kernel size = 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "\n",
        "        # C5: Fully connected convolutional layer (flattened previous conv output)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)  # 16*4*4 is the flattened output from conv2\n",
        "\n",
        "        # F6: Fully connected layer\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "\n",
        "        # Output layer: 10 classes for MNIST digits\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # C1: Convolution + ReLU + Average Pooling\n",
        "        x = F.relu(self.conv1(x))  # Input: 28x28x1 â†’ Output: 24x24x6\n",
        "        x = F.avg_pool2d(x, 2)     # Output: 12x12x6\n",
        "\n",
        "        # C3: Convolution + ReLU + Average Pooling\n",
        "        x = F.relu(self.conv2(x))  # Output: 8x8x16\n",
        "        x = F.avg_pool2d(x, 2)     # Output: 4x4x16\n",
        "\n",
        "        # Flatten the output from conv layers (prepare for fully connected layers)\n",
        "        x = torch.flatten(x, 1)    # Output: 16*4*4\n",
        "\n",
        "        # C5: Fully connected layer + ReLU\n",
        "        x = F.relu(self.fc1(x))    # Output: 120\n",
        "\n",
        "        # F6: Fully connected layer + ReLU\n",
        "        x = F.relu(self.fc2(x))    # Output: 84\n",
        "\n",
        "        # Output layer: Log Softmax for classification\n",
        "        x = F.log_softmax(self.fc3(x), dim=1)  # Output: 10\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Stvf8eBYDgKF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "\n",
        "for epoch in range(3):\n",
        "  running_loss = 0\n",
        "  for i, data in enumerate(trainloader, 0):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(inputs)\n",
        "    loss = criteria(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 100 == 99:    # print every 100 mini-batches\n",
        "        print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 10:.3f}')\n",
        "        running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-GVSouKRPxx",
        "outputId": "da9065e0-9dd3-43a7-8d0a-12768a8861e8"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 100] loss: 13.153\n",
            "[1, 200] loss: 4.936\n",
            "[1, 300] loss: 4.201\n",
            "[1, 400] loss: 3.322\n",
            "[1, 500] loss: 2.698\n",
            "[1, 600] loss: 2.397\n",
            "[1, 700] loss: 1.989\n",
            "[1, 800] loss: 1.895\n",
            "[1, 900] loss: 1.747\n",
            "[2, 100] loss: 1.448\n",
            "[2, 200] loss: 1.358\n",
            "[2, 300] loss: 1.309\n",
            "[2, 400] loss: 1.213\n",
            "[2, 500] loss: 1.154\n",
            "[2, 600] loss: 1.194\n",
            "[2, 700] loss: 1.050\n",
            "[2, 800] loss: 1.110\n",
            "[2, 900] loss: 1.005\n",
            "[3, 100] loss: 0.875\n",
            "[3, 200] loss: 0.851\n",
            "[3, 300] loss: 0.798\n",
            "[3, 400] loss: 0.921\n",
            "[3, 500] loss: 0.876\n",
            "[3, 600] loss: 0.918\n",
            "[3, 700] loss: 0.767\n",
            "[3, 800] loss: 0.776\n",
            "[3, 900] loss: 0.775\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './mnist_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "sHfaRIW_UOIx"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN42QegSVHtP",
        "outputId": "37b1090c-3cba-4b22-dc82-0f53abd55ca8"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "3Gjrcd7lXtXr"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ZbgCX0XzZn",
        "outputId": "daba50bd-df87-4cd4-e677-3711d0edf333"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
              "         4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
              "         4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3]),\n",
              " torch.Size([64, 1, 28, 28]))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)"
      ],
      "metadata": {
        "id": "QNV7MW_xYFKU"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyRx99dGYPYv",
        "outputId": "88b81a4e-615d-44a9-8d6d-200e879304e6"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIQLGXvyYptF",
        "outputId": "16eac03e-f301-4c21-b46e-d87f1968fa6e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([-8.1589e-04, -1.9550e-05, -7.6515e-04, -1.4305e-05, -2.5198e-04,\n",
              "        -3.9457e-05, -5.0459e-03, -6.6647e-02, -5.5961e-01, -8.0458e-04,\n",
              "        -1.8596e-05, -1.7594e-04, -5.3189e-04, -3.3259e-05, -1.9669e-05,\n",
              "        -7.9277e-03, -1.1602e-03, -3.2352e-03, -2.6042e-02, -4.3272e-05,\n",
              "        -1.6668e-02, -1.1288e-04, -1.3708e-04, -2.2802e-04, -1.4909e-03,\n",
              "        -6.4373e-06, -5.6648e-03, -1.1921e-06, -3.3378e-05, -2.4597e-03,\n",
              "        -5.7219e-05, -3.1825e-03, -4.8875e-05, -6.4402e-03, -6.2994e-04,\n",
              "        -1.1028e-03, -9.6033e-02, -1.2898e-04, -9.6111e-02, -1.6295e-04,\n",
              "        -1.1712e-02, -9.4842e-02, -3.3497e-05, -2.6715e-03, -2.9768e-03,\n",
              "        -2.4101e-02, -1.7811e-03, -9.2476e-04, -3.6955e-06, -6.0318e-05,\n",
              "        -5.1473e-04, -1.8239e-05, -3.9617e-04, -3.1206e-02, -1.1325e-05,\n",
              "        -9.3337e-05, -2.3842e-07, -4.2489e-04, -1.3756e-04, -4.2911e-03,\n",
              "        -1.6195e-02, -1.2407e-02, -3.0939e-01, -4.7964e-03],\n",
              "       grad_fn=<MaxBackward0>),\n",
              "indices=tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
              "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
              "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)"
      ],
      "metadata": {
        "id": "AFZ-qmrKYQhP"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCgyAeX0YiBV",
        "outputId": "55030e89-1f4d-4b04-f91c-b3103ac68982"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-8.1589e-04, -1.9550e-05, -7.6515e-04, -1.4305e-05, -2.5198e-04,\n",
              "         -3.9457e-05, -5.0459e-03, -6.6647e-02, -5.5961e-01, -8.0458e-04,\n",
              "         -1.8596e-05, -1.7594e-04, -5.3189e-04, -3.3259e-05, -1.9669e-05,\n",
              "         -7.9277e-03, -1.1602e-03, -3.2352e-03, -2.6042e-02, -4.3272e-05,\n",
              "         -1.6668e-02, -1.1288e-04, -1.3708e-04, -2.2802e-04, -1.4909e-03,\n",
              "         -6.4373e-06, -5.6648e-03, -1.1921e-06, -3.3378e-05, -2.4597e-03,\n",
              "         -5.7219e-05, -3.1825e-03, -4.8875e-05, -6.4402e-03, -6.2994e-04,\n",
              "         -1.1028e-03, -9.6033e-02, -1.2898e-04, -9.6111e-02, -1.6295e-04,\n",
              "         -1.1712e-02, -9.4842e-02, -3.3497e-05, -2.6715e-03, -2.9768e-03,\n",
              "         -2.4101e-02, -1.7811e-03, -9.2476e-04, -3.6955e-06, -6.0318e-05,\n",
              "         -5.1473e-04, -1.8239e-05, -3.9617e-04, -3.1206e-02, -1.1325e-05,\n",
              "         -9.3337e-05, -2.3842e-07, -4.2489e-04, -1.3756e-04, -4.2911e-03,\n",
              "         -1.6195e-02, -1.2407e-02, -3.0939e-01, -4.7964e-03],\n",
              "        grad_fn=<MaxBackward0>),\n",
              " tensor([7, 2, 1, 0, 4, 1, 4, 9, 6, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
              "         4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
              "         4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = net(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "# Accuracy of the CNN network on the 10000 test images: 97 % Diff: epoch only 2\n",
        "# Accuracy of the LeNet network on the 10000 test images: 98 % epoch only 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgj4lxlYYkEe",
        "outputId": "b7244000-5b9a-4610-d762-cd89a28a5124"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 98 %\n"
          ]
        }
      ]
    }
  ]
}